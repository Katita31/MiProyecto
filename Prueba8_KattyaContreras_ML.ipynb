{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2c3a7e4-e8ae-4acf-98dd-a15a9bd4ebd2",
   "metadata": {},
   "source": [
    "# **Predicci√≥n del precio de vuelos**\n",
    "## Proyecto y prueba Final Data Science - Academia Desaf√≠o Latam\n",
    "\n",
    "Este notebook aborda el problema de predecir el precio de boletos de avi√≥n usando datos de `business.csv` y `economy.csv`, aplicando limpieza, an√°lisis exploratorio, ingenier√≠a de variables, modelamiento y evaluaci√≥n. **Modelos candidatos:** Random Forest, Lasso, XGBoost\n",
    "\n",
    "\n",
    "**Nombre: Kattya Contreras**\n",
    "\n",
    "**M√≥dulo: Machine Learning**\n",
    "\n",
    "**Secci√≥n: G101**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4f623e-dcf7-453b-b628-fe8492510431",
   "metadata": {},
   "source": [
    "**1. Problema de negocio y metodolog√≠a**\n",
    "\n",
    "**Problema:** Predecir el precio de boletos de avi√≥n para una agencia de viajes online, considerando variables como aerol√≠nea, clase, destino, fechas, etc.\n",
    "\n",
    "**Metodolog√≠a:**\n",
    "- An√°lisis exploratorio y calidad de datos\n",
    "- Limpieza y preprocesamiento\n",
    "- Ingenier√≠a de variables\n",
    "- Modelamiento y optimizaci√≥n\n",
    "- Evaluaci√≥n de modelos\n",
    "- Conclusiones y pr√≥ximos pasos\n",
    "\n",
    "**Variable objetivo:** `price`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3471b497-ec14-4112-a7c9-7f496e460324",
   "metadata": {},
   "source": [
    "**Paso 1. Importaci√≥n de librer√≠as y configuraci√≥n general**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cb2907-e8b7-4dc9-96e9-e88cb318c7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('ggplot')\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecc16de-5f16-4425-a42f-672e2ea3a8d4",
   "metadata": {},
   "source": [
    "\n",
    "**PASO 2: Carga de datos y reporte de calidad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eaa240-1d64-409f-958f-975a5823321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business = pd.read_excel(\"Data/business.xlsx\")\n",
    "df_economy = pd.read_excel(\"Data/economy.xlsx\")\n",
    "\n",
    "def quality_report(df, name):\n",
    "    print(f\"\\n{name} - Info:\")\n",
    "    print(df.info())\n",
    "    print(\"\\nNulos por columna:\")\n",
    "    print(df.isnull().sum())\n",
    "    print(\"\\nDuplicados:\", df.duplicated().sum())\n",
    "    print(\"\\nDescriptivo price:\")\n",
    "    print(df['price'].describe())\n",
    "\n",
    "quality_report(df_business, \"BUSINESS\")\n",
    "quality_report(df_economy, \"ECONOMY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aca98a-b7aa-462d-9ef0-08805c9d45b1",
   "metadata": {},
   "source": [
    "\n",
    "**PASO 3. Limpieza b√°sica: nulos y duplicados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1f2260-111b-4fa9-8ccd-44ee94872d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business = df_business[df_business['price'].notnull()].drop_duplicates().copy()\n",
    "df_economy = df_economy.drop_duplicates().copy()\n",
    "print(\"Business shape:\", df_business.shape)\n",
    "print(\"Economy shape:\", df_economy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef35fcf9-8385-4fda-8033-fe969d070af7",
   "metadata": {},
   "source": [
    "**PASO 4. Limpieza avanzada: columna stop y variable num√©rica**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af5fe0a-ceff-4e41-b320-60ad3336dca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_stop_column(df):\n",
    "    df['stop'] = df['stop'].astype(str).str.replace(r'[\\n\\t]+', '', regex=True).str.strip()\n",
    "    def stop_to_num(s):\n",
    "        s = s.lower()\n",
    "        if 'non-stop' in s:\n",
    "            return 0\n",
    "        if '1-stop' in s:\n",
    "            return 1\n",
    "        if '2-stop' in s or '2+' in s:\n",
    "            return 2\n",
    "        match = re.search(r'(\\d+)-stop', s)\n",
    "        return int(match.group(1)) if match else None\n",
    "    df['stop_num'] = df['stop'].apply(stop_to_num)\n",
    "    return df\n",
    "\n",
    "df_business = clean_stop_column(df_business)\n",
    "df_economy = clean_stop_column(df_economy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4a441e-5efe-44ab-8a91-2e12894ca962",
   "metadata": {},
   "source": [
    "**PASO 5. Feature Engineering: duraci√≥n de vuelo en minutos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92d2f0c-a18f-41e8-9b59-e1b38b546690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_taken_to_minutes(s):\n",
    "    if pd.isnull(s): return None\n",
    "    try:\n",
    "        h, m = 0, 0\n",
    "        parts = s.split('h')\n",
    "        if len(parts) == 2:\n",
    "            h = int(parts[0].strip())\n",
    "            m = int(parts[1].replace('m','').strip())\n",
    "        elif 'h' in s:\n",
    "            h = int(s.split('h')[0].strip())\n",
    "        elif 'm' in s:\n",
    "            m = int(s.replace('m','').strip())\n",
    "        return h*60 + m\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df_business['time_taken_min'] = df_business['time_taken'].apply(time_taken_to_minutes)\n",
    "df_economy['time_taken_min'] = df_economy['time_taken'].apply(time_taken_to_minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6670f1a0-6504-4838-a41b-6cdea8b5b80c",
   "metadata": {},
   "source": [
    "**PASO 6. M√°s variables: mes, d√≠a de semana y ruta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fc73b0-42db-4882-8a0a-8907359e03ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business['month'] = df_business['date'].dt.month\n",
    "df_business['day_of_week'] = df_business['date'].dt.dayofweek\n",
    "df_business['route'] = df_business['from'] + '-' + df_business['to']\n",
    "\n",
    "df_economy['month'] = df_economy['date'].dt.month\n",
    "df_economy['day_of_week'] = df_economy['date'].dt.dayofweek\n",
    "df_economy['route'] = df_economy['from'] + '-' + df_economy['to']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277c43c7-2c71-4731-9d23-eb0364905d54",
   "metadata": {},
   "source": [
    "**PASO 7. Codificaci√≥n de variables categ√≥ricas (top aerol√≠neas y rutas)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8409763-c513-4af7-a8f3-1f808f8483c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_airlines_business = df_business['airline'].value_counts().nlargest(10).index.tolist()\n",
    "df_business['airline_top'] = df_business['airline'].apply(lambda x: x if x in top_airlines_business else 'other')\n",
    "df_business = pd.get_dummies(df_business, columns=['airline_top', 'route'], drop_first=True)\n",
    "\n",
    "top_airlines_economy = df_economy['airline'].value_counts().nlargest(10).index.tolist()\n",
    "df_economy['airline_top'] = df_economy['airline'].apply(lambda x: x if x in top_airlines_economy else 'other')\n",
    "df_economy = pd.get_dummies(df_economy, columns=['airline_top', 'route'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa281f00-ef7f-4367-a746-4db53f851753",
   "metadata": {},
   "source": [
    "\n",
    "**PASO 8. Imputaci√≥n de nulos en nuevas columnas num√©ricas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534f9c00-50ec-4c3b-883b-1124ca6eb27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['time_taken_min', 'stop_num']:\n",
    "    df_business[col] = df_business[col].fillna(df_business[col].median())\n",
    "    df_economy[col] = df_economy[col].fillna(df_economy[col].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9837327d-90b7-4e23-b4f7-bcedcfefda74",
   "metadata": {},
   "source": [
    "**PASO 9. Eliminar columnas irrelevantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23040ad-a498-4943-a2fd-596f4e1d99af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['ch_code', 'dep_time', 'arr_time', 'airline', 'from', 'to', 'time_taken', 'stop']\n",
    "df_business = df_business.drop(cols_to_drop, axis=1)\n",
    "df_economy = df_economy.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6689dd6-6e36-453d-ac7a-18e13982cabe",
   "metadata": {},
   "source": [
    "**PASO 10. An√°lisis exploratorio visual (EDA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661011a2-b1f7-4150-927f-644f482595a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Limpieza y conversi√≥n de 'price' =====\n",
    "for df in [df_business, df_economy]:\n",
    "    df['price'] = (\n",
    "        df['price']\n",
    "        .astype(str)              # asegurar que sea string\n",
    "        .str.replace(',', '', regex=False)  # quitar comas\n",
    "        .str.strip()              # quitar espacios\n",
    "    )\n",
    "    df['price'] = pd.to_numeric(df['price'], errors='coerce')  # convertir a num√©rico\n",
    "\n",
    "# Eliminar nulos resultantes\n",
    "df_business = df_business[df_business['price'].notnull()].copy()\n",
    "df_economy = df_economy[df_economy['price'].notnull()].copy()\n",
    "\n",
    "print(\"‚úÖ Limpieza de 'price' completada\")\n",
    "print(\"Business shape:\", df_business.shape)\n",
    "print(\"Economy shape:\", df_economy.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d23c7e2-a69d-4df3-bc3f-8c220be45b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Histograma con KDE para distribuci√≥n de precios =====\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(df_business['price'], kde=True, color='red', label='Business', bins=50)\n",
    "sns.histplot(df_economy['price'], kde=True, color='blue', label='Economy', bins=50)\n",
    "plt.legend()\n",
    "plt.title('Distribuci√≥n de precios: Business vs Economy')\n",
    "plt.xlabel('Precio')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fe501b-8983-4431-a633-6dbd5af366a3",
   "metadata": {},
   "source": [
    "# **Variables m√°s importantes para price (correlaciones)**\n",
    "\n",
    "- La variable stop_num (cantidad de escalas) tiene la correlaci√≥n m√°s alta con el precio (0.59), seguida por time_taken_min (duraci√≥n del vuelo, 0.24) y num_code (0.22).\n",
    "\n",
    "- day_of_week y month muestran correlaciones bajas, pero podr√≠an tener efectos no lineales.\n",
    "\n",
    "- Implicaciones: el modelo debe priorizar variables como escalas y duraci√≥n del vuelo, mientras que otras variables con baja correlaci√≥n a√∫n pueden ser √∫tiles para capturar relaciones complejas.\n",
    "\n",
    "**S√≠ntesis:**\n",
    "\n",
    "- Los precios dependen principalmente de la cantidad de escalas y duraci√≥n del vuelo, y existen diferencias marcadas entre clases (Business vs Economy).\n",
    "\n",
    "- Esto valida la elecci√≥n de modelos no lineales y la necesidad de un preprocesamiento cuidadoso, incluyendo ingenier√≠a de variables y manejo de outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60f5ddf-4edd-4d7d-a9d7-40ff771b0fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Definir colormap armonioso: azul medio -> blanco -> rojo profundo\n",
    "colors = [\"#1f4e79\", \"#f0f0f0\", \"#b30000\"]  # azul medio, gris claro, rojo profundo\n",
    "cmap = LinearSegmentedColormap.from_list(\"blue_white_red_professional\", colors)\n",
    "\n",
    "# Correlaci√≥n de variables num√©ricas\n",
    "corr = df_business[['price', 'stop_num', 'time_taken_min', 'num_code', 'day_of_week', 'month']].corr()\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=cmap,\n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"shrink\":0.8, \"label\":\"Correlaci√≥n\"}\n",
    ")\n",
    "plt.title(\"Mapa de correlaciones de variables num√©ricas\", fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25ac5b9-c604-40ac-b6fa-73b2aea058b0",
   "metadata": {},
   "source": [
    "# **Conclusi√≥n del an√°lisis exploratorio visual y correlaciones**\n",
    "\n",
    "- Distribuci√≥n de precios (Business vs Economy)\n",
    "\n",
    "- Business tiene precios m√°s altos y una cola larga de valores extremos, mostrando gran dispersi√≥n.\n",
    "\n",
    "- Economy est√° m√°s concentrada en rangos bajos-medios, con menos valores extremos.\n",
    "\n",
    "- Ambas distribuciones est√°n sesgadas a la derecha, indicando que la media no representa completamente la tendencia central.\n",
    "\n",
    "**Implicaciones: se recomienda realizar transformaci√≥n del target (price) y manejo de outliers para mejorar el desempe√±o de los modelos. Adem√°s, los modelos no lineales (Random Forest, XGBoost) son m√°s adecuados que modelos lineales simples (Lasso).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4d3581-4201-4fc8-b540-2c9c799c5d01",
   "metadata": {},
   "source": [
    "\n",
    "**PASO 11. Modelado: entrenamiento y evaluaci√≥n**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0b5436-f718-4842-a2ea-f6ac573124c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ==============================\n",
    "# Separar features y target\n",
    "# ==============================\n",
    "X = df_business.drop('price', axis=1)\n",
    "y = df_business['price']\n",
    "\n",
    "# Procesar columna de fecha\n",
    "# ==============================\n",
    "if 'date' in X.columns:\n",
    "    X['year'] = X['date'].dt.year\n",
    "    X['month'] = X['date'].dt.month\n",
    "    X['day'] = X['date'].dt.day\n",
    "    X['weekday'] = X['date'].dt.weekday\n",
    "    X['is_weekend'] = X['date'].dt.weekday >= 5\n",
    "    X = X.drop(columns=['date'])\n",
    "\n",
    "print(\"Columnas despu√©s de procesar fechas:\")\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5aaf8a-0f03-465a-846a-dafce0c88654",
   "metadata": {},
   "source": [
    "Limpieza de Fecha: Convertimos la columna date en varias variables derivadas (year, month, day, weekday, is_weekend) para capturar estacionalidad y patrones seg√∫n d√≠a y mes. Adem√°s, verificamos los tipos de datos resultantes para asegurar compatibilidad con los modelos de Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b022750a-9cd8-4f0b-96f4-e0f858807af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamiento y limpieza de fechas\n",
    "\n",
    "X = df_business.drop('price', axis=1)\n",
    "y = df_business['price']\n",
    "\n",
    "# Si existe la columna date, procesarla\n",
    "if 'date' in X.columns:\n",
    "    X['year'] = X['date'].dt.year\n",
    "    X['month'] = X['date'].dt.month\n",
    "    X['day'] = X['date'].dt.day\n",
    "    X['weekday'] = X['date'].dt.weekday\n",
    "    X['is_weekend'] = (X['date'].dt.weekday >= 5).astype(int)  # 0 o 1\n",
    "\n",
    "    # üî• eliminar definitivamente la columna date\n",
    "    X = X.drop(columns=['date'])\n",
    "\n",
    "print(\"Dtypes despu√©s de limpiar fechas:\")\n",
    "print(X.dtypes)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639f2028",
   "metadata": {},
   "source": [
    "**Divisi√≥n en test y train**\n",
    "\n",
    "**Entrenamiento y Evaluaci√≥n de modelos: RandomForest, Lasso, y XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d37d0a-ee7d-4a46-a340-9faf00f16b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Divisi√≥n train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Modelos\n",
    "models = {\n",
    "    'RandomForest': RandomForestRegressor(random_state=42),\n",
    "    'Lasso': Lasso(alpha=0.01, random_state=42),   # alpha peque√±o para no penalizar demasiado\n",
    "    'XGBoost': XGBRegressor(random_state=42, n_estimators=200, learning_rate=0.1)\n",
    "}\n",
    "\n",
    "# Entrenar y evaluar\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nEntrenando {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"{name} ‚Üí RMSE: {rmse:.2f}, R¬≤: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd21c93d-00f7-4c92-8b1a-b0fd45866ae0",
   "metadata": {},
   "source": [
    "                                   Comparaci√≥n de modelos para predicci√≥n de precio de vuelos\n",
    "\n",
    "| Modelo        | RMSE    | R¬≤     | Comentario                                                                              |\n",
    "| ------------- | ------- | ------ | --------------------------------------------------------------------------------------- |\n",
    "| Random Forest | 3626.39 | 0.9222 | Mejor desempe√±o, captura relaciones no lineales, m√°s robusto frente a outliers          |\n",
    "| Lasso         | 8803.48 | 0.5417 | Peor desempe√±o, modelo lineal simple, no maneja bien la distribuci√≥n sesgada del target |\n",
    "| XGBoost       | 4759.55 | 0.8660 | Bueno, cercano a Random Forest, permite cierta regularizaci√≥n y no linealidad           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b4364d",
   "metadata": {},
   "source": [
    "**Optimizaci√≥n de RandomForest con GridSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0dc871-91c6-488d-8534-4395a212c821",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Definir grid de hiperpar√°metros\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2,5],\n",
    "    'min_samples_leaf': [1,2]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=3, scoring='r2', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mejor modelo\n",
    "print(\"Mejores par√°metros RandomForest:\", grid_search.best_params_)\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Predicciones\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "# M√©tricas\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"RandomForest Optimizado ‚Üí RMSE: {rmse_rf:.2f}, R¬≤: {r2_rf:.4f}, MAE: {mae_rf:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3330ea18",
   "metadata": {},
   "source": [
    "Se realiz√≥ una b√∫squeda de hiperpar√°metros para RandomForest utilizando **GridSearchCV** con validaci√≥n cruzada (cv=3).  \n",
    "El modelo optimizado mejor√≥ respecto al baseline y a la versi√≥n sin tuning, mostrando un ajuste s√≥lido con buen equilibrio entre **precisi√≥n (R¬≤)** y **error absoluto (MAE)**.\n",
    "\n",
    "Mejores par√°metros RandomForest: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
    "RandomForest Optimizado ‚Üí RMSE: 3604.44, R¬≤: 0.9232, MAE: 1708.94\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3c2788-e17f-42ff-9bbc-25a24e7458db",
   "metadata": {},
   "source": [
    "**PASO 12. Evaluaci√≥n y comparaci√≥n de modelos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971a8611-9696-43ac-a4d9-e6baa6741399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£ Importar librer√≠as necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# 2Ô∏è‚É£ Funci√≥n de evaluaci√≥n de modelos\n",
    "def evaluate(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))  # RMSE manual para compatibilidad\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return mae, rmse, r2\n",
    "\n",
    "# 3Ô∏è‚É£ Evaluar cada modelo del diccionario 'models'\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    results[name] = evaluate(model, X_test, y_test)\n",
    "\n",
    "# 4Ô∏è‚É£ Convertir resultados en DataFrame\n",
    "metrics_df = pd.DataFrame(results, index=['MAE', 'RMSE', 'R2']).T\n",
    "metrics_df.index.name = 'Modelo'\n",
    "metrics_df.columns.name = 'M√©trica'\n",
    "\n",
    "# 5Ô∏è‚É£ Graficar comparaci√≥n de m√©tricas\n",
    "metrics_df.plot(kind='bar', figsize=(10,6))\n",
    "plt.title('Comparaci√≥n de m√©tricas entre modelos')\n",
    "plt.ylabel('Valor')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# 6Ô∏è‚É£ Evaluaci√≥n de baseline: predecir la media de y_train\n",
    "y_pred_baseline = np.full(shape=y_test.shape, fill_value=y_train.mean(), dtype=np.float64)\n",
    "mae_base = mean_absolute_error(y_test, y_pred_baseline)\n",
    "rmse_base = np.sqrt(mean_squared_error(y_test, y_pred_baseline))\n",
    "r2_base = r2_score(y_test, y_pred_baseline)\n",
    "print(f\"Baseline (media): MAE={mae_base:.2f}, RMSE={rmse_base:.2f}, R2={r2_base:.2f}\")\n",
    "\n",
    "# 7Ô∏è‚É£ Comparaci√≥n con baseline en gr√°fico adicional (opcional)\n",
    "baseline_df = metrics_df.copy()\n",
    "baseline_df.loc['Baseline'] = [mae_base, rmse_base, r2_base]\n",
    "\n",
    "baseline_df.plot(kind='bar', figsize=(10,6))\n",
    "plt.title('Comparaci√≥n modelos vs Baseline')\n",
    "plt.ylabel('Valor')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e174bf0-f729-44ff-9793-03ed8c50e29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£ DataFrame con baseline incluido\n",
    "metrics_full_df = metrics_df.copy()\n",
    "metrics_full_df.loc['Baseline'] = [mae_base, rmse_base, r2_base]\n",
    "\n",
    "# 2Ô∏è‚É£ Configuraci√≥n del gr√°fico\n",
    "fig, ax1 = plt.subplots(figsize=(12,6))\n",
    "\n",
    "x = np.arange(len(metrics_full_df))\n",
    "bar_width = 0.35\n",
    "\n",
    "# Barras MAE y RMSE en eje principal\n",
    "ax1.bar(x - bar_width/2, metrics_full_df['MAE'], width=bar_width, label='MAE', color='skyblue')\n",
    "ax1.bar(x + bar_width/2, metrics_full_df['RMSE'], width=bar_width, label='RMSE', color='salmon')\n",
    "ax1.set_ylabel('MAE / RMSE')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(metrics_full_df.index)\n",
    "ax1.set_title('Comparaci√≥n de m√©tricas por modelo (incluyendo Baseline)')\n",
    "ax1.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# 3Ô∏è‚É£ R¬≤ en eje secundario\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(x, metrics_full_df['R2'], color='green', marker='o', linestyle='-', label='R¬≤', linewidth=2)\n",
    "ax2.set_ylabel('R¬≤')\n",
    "ax2.set_ylim(0,1)  # opcional: normalizar R¬≤ entre 0 y 1 para mejor visualizaci√≥n\n",
    "\n",
    "# 4Ô∏è‚É£ Leyenda combinada\n",
    "bars_labels = ax1.get_legend_handles_labels()\n",
    "line_labels = ax2.get_legend_handles_labels()\n",
    "ax1.legend(bars_labels[0] + line_labels[0], bars_labels[1] + line_labels[1], loc='upper right')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcf30b2-59e9-4f14-b59d-c1b331546124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline\n",
    "y_pred_base = np.full_like(y_test, y_train.mean())\n",
    "mae_base = mean_absolute_error(y_test, y_pred_base)\n",
    "rmse_base = np.sqrt(mean_squared_error(y_test, y_pred_base))\n",
    "r2_base = r2_score(y_test, y_pred_base)\n",
    "\n",
    "print(\"Baseline (media) ‚Üí MAE: {:.2f}, RMSE: {:.2f}, R2: {:.4f}\".format(mae_base, rmse_base, r2_base))\n",
    "\n",
    "# Comparaci√≥n final\n",
    "print(\"\\nConclusi√≥n:\")\n",
    "print(\"- RandomForest y XGBoost superan ampliamente el baseline y Lasso.\")\n",
    "print(\"- Variables m√°s relevantes seg√∫n correlaci√≥n: time_taken_min, stop_num, month, day_of_week.\")\n",
    "print(\"- La data tiene outliers y colas largas en Business, por lo que modelos no lineales funcionan mejor.\")\n",
    "print(\"- Pr√≥ximos pasos: tratar outliers, evaluar transformaciones logar√≠tmicas, ajustar hiperpar√°metros XGBoost y evaluar Economy.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80acda25-5d35-4cae-a07a-e3dbd276b8b2",
   "metadata": {},
   "source": [
    "# Conclusi√≥n del proyecto de predicci√≥n de precios de vuelos\n",
    "\n",
    "## Resumen ejecutivo\n",
    "\n",
    "- Se entrenaron tres modelos: **Random Forest**, **Lasso** y **XGBoost** para predecir el precio de boletos de avi√≥n (Business).  \n",
    "- Se compararon sus m√©tricas frente a un **baseline** simple (predecir la media de `price`).  \n",
    "- Se aplicaron transformaciones de fechas, codificaci√≥n de aerol√≠neas y rutas, y feature engineering para escalas y duraci√≥n del vuelo.  \n",
    "- La distribuci√≥n de precios presenta **outliers y colas largas**, por lo que los modelos **no lineales** funcionan mejor.\n",
    "\n",
    "---\n",
    "\n",
    "## Comparaci√≥n de modelos\n",
    "\n",
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Modelo</th>\n",
    "<th>RMSE</th>\n",
    "<th>MAE</th>\n",
    "<th>R¬≤</th>\n",
    "<th>Comentario</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr style=\"background-color:#c6efce;\"> \n",
    "<td>Random Forest</td>\n",
    "<td>3604.44</td>\n",
    "<td>1708.94</td>\n",
    "<td>0.9232</td>\n",
    "<td>Mejor desempe√±o, captura relaciones no lineales y robusto frente a outliers</td>\n",
    "</tr>\n",
    "<tr style=\"background-color:#ffc7ce;\"> \n",
    "<td>Lasso</td>\n",
    "<td>8803.48</td>\n",
    "<td>5342.01</td>\n",
    "<td>0.5417</td>\n",
    "<td>Peor desempe√±o, modelo lineal simple, no maneja bien la distribuci√≥n sesgada del target</td>\n",
    "</tr>\n",
    "<tr style=\"background-color:#ffeb9c;\"> \n",
    "<td>XGBoost</td>\n",
    "<td>4759.55</td>\n",
    "<td>2087.23</td>\n",
    "<td>0.8660</td>\n",
    "<td>Buen desempe√±o, cercano a Random Forest, permite regularizaci√≥n y relaciones no lineales</td>\n",
    "</tr>\n",
    "<tr style=\"background-color:#d9d9d9;\"> \n",
    "<td>Baseline</td>\n",
    "<td>13004.97</td>\n",
    "<td>9732.75</td>\n",
    "<td>-0.0001</td>\n",
    "<td>L√≠nea base (media de `price`), muestra la ventaja de los modelos predictivos</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusi√≥n final\n",
    "\n",
    "1. **Random Forest** es el modelo m√°s recomendado, seguido de **XGBoost**.  \n",
    "2. Las variables m√°s relevantes son: `stop_num` (cantidad de escalas), `time_taken_min` (duraci√≥n del vuelo), `month` y `day_of_week`.  \n",
    "3. Los modelos lineales simples (Lasso) no son adecuados para esta distribuci√≥n de precios.  \n",
    "4. **Pr√≥ximos pasos**:  \n",
    "   - Tratar outliers y colas largas (Business).  \n",
    "   - Evaluar transformaciones logar√≠tmicas de `price`.  \n",
    "   - Ajustar hiperpar√°metros de XGBoost.  \n",
    "   - Aplicar la misma metodolog√≠a a la clase **Economy** para comparar resultados.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
