{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2c3a7e4-e8ae-4acf-98dd-a15a9bd4ebd2",
   "metadata": {},
   "source": [
    "# **Predicción del precio de vuelos**\n",
    "## Proyecto y prueba Final Data Science - Academia Desafío Latam\n",
    "\n",
    "Este notebook aborda el problema de predecir el precio de boletos de avión usando datos de `business.csv` y `economy.csv`, aplicando limpieza, análisis exploratorio, ingeniería de variables, modelamiento y evaluación. **Modelos candidatos:** Random Forest, Lasso, XGBoost\n",
    "\n",
    "\n",
    "**Nombre: Kattya Contreras**\n",
    "\n",
    "**Módulo: Machine Learning**\n",
    "\n",
    "**Sección: G101**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4f623e-dcf7-453b-b628-fe8492510431",
   "metadata": {},
   "source": [
    "**1. Problema de negocio y metodología**\n",
    "\n",
    "**Problema:** Predecir el precio de boletos de avión para una agencia de viajes online, considerando variables como aerolínea, clase, destino, fechas, etc.\n",
    "\n",
    "**Metodología:**\n",
    "- Análisis exploratorio y calidad de datos\n",
    "- Limpieza y preprocesamiento\n",
    "- Ingeniería de variables\n",
    "- Modelamiento y optimización\n",
    "- Evaluación de modelos\n",
    "- Conclusiones y próximos pasos\n",
    "\n",
    "**Variable objetivo:** `price`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3471b497-ec14-4112-a7c9-7f496e460324",
   "metadata": {},
   "source": [
    "**Paso 1. Importación de librerías y configuración general**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cb2907-e8b7-4dc9-96e9-e88cb318c7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('ggplot')\n",
    "print(\"✅ Librerías importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecc16de-5f16-4425-a42f-672e2ea3a8d4",
   "metadata": {},
   "source": [
    "\n",
    "**PASO 2: Carga de datos y reporte de calidad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eaa240-1d64-409f-958f-975a5823321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business = pd.read_excel(\"Data/business.xlsx\")\n",
    "df_economy = pd.read_excel(\"Data/economy.xlsx\")\n",
    "\n",
    "def quality_report(df, name):\n",
    "    print(f\"\\n{name} - Info:\")\n",
    "    print(df.info())\n",
    "    print(\"\\nNulos por columna:\")\n",
    "    print(df.isnull().sum())\n",
    "    print(\"\\nDuplicados:\", df.duplicated().sum())\n",
    "    print(\"\\nDescriptivo price:\")\n",
    "    print(df['price'].describe())\n",
    "\n",
    "quality_report(df_business, \"BUSINESS\")\n",
    "quality_report(df_economy, \"ECONOMY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aca98a-b7aa-462d-9ef0-08805c9d45b1",
   "metadata": {},
   "source": [
    "\n",
    "**PASO 3. Limpieza básica: nulos y duplicados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1f2260-111b-4fa9-8ccd-44ee94872d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business = df_business[df_business['price'].notnull()].drop_duplicates().copy()\n",
    "df_economy = df_economy.drop_duplicates().copy()\n",
    "print(\"Business shape:\", df_business.shape)\n",
    "print(\"Economy shape:\", df_economy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef35fcf9-8385-4fda-8033-fe969d070af7",
   "metadata": {},
   "source": [
    "**PASO 4. Limpieza avanzada: columna stop y variable numérica**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af5fe0a-ceff-4e41-b320-60ad3336dca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_stop_column(df):\n",
    "    df['stop'] = df['stop'].astype(str).str.replace(r'[\\n\\t]+', '', regex=True).str.strip()\n",
    "    def stop_to_num(s):\n",
    "        s = s.lower()\n",
    "        if 'non-stop' in s:\n",
    "            return 0\n",
    "        if '1-stop' in s:\n",
    "            return 1\n",
    "        if '2-stop' in s or '2+' in s:\n",
    "            return 2\n",
    "        match = re.search(r'(\\d+)-stop', s)\n",
    "        return int(match.group(1)) if match else None\n",
    "    df['stop_num'] = df['stop'].apply(stop_to_num)\n",
    "    return df\n",
    "\n",
    "df_business = clean_stop_column(df_business)\n",
    "df_economy = clean_stop_column(df_economy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4a441e-5efe-44ab-8a91-2e12894ca962",
   "metadata": {},
   "source": [
    "**PASO 5. Feature Engineering: duración de vuelo en minutos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92d2f0c-a18f-41e8-9b59-e1b38b546690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_taken_to_minutes(s):\n",
    "    if pd.isnull(s): return None\n",
    "    try:\n",
    "        h, m = 0, 0\n",
    "        parts = s.split('h')\n",
    "        if len(parts) == 2:\n",
    "            h = int(parts[0].strip())\n",
    "            m = int(parts[1].replace('m','').strip())\n",
    "        elif 'h' in s:\n",
    "            h = int(s.split('h')[0].strip())\n",
    "        elif 'm' in s:\n",
    "            m = int(s.replace('m','').strip())\n",
    "        return h*60 + m\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df_business['time_taken_min'] = df_business['time_taken'].apply(time_taken_to_minutes)\n",
    "df_economy['time_taken_min'] = df_economy['time_taken'].apply(time_taken_to_minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6670f1a0-6504-4838-a41b-6cdea8b5b80c",
   "metadata": {},
   "source": [
    "**PASO 6. Más variables: mes, día de semana y ruta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fc73b0-42db-4882-8a0a-8907359e03ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business['month'] = df_business['date'].dt.month\n",
    "df_business['day_of_week'] = df_business['date'].dt.dayofweek\n",
    "df_business['route'] = df_business['from'] + '-' + df_business['to']\n",
    "\n",
    "df_economy['month'] = df_economy['date'].dt.month\n",
    "df_economy['day_of_week'] = df_economy['date'].dt.dayofweek\n",
    "df_economy['route'] = df_economy['from'] + '-' + df_economy['to']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277c43c7-2c71-4731-9d23-eb0364905d54",
   "metadata": {},
   "source": [
    "**PASO 7. Codificación de variables categóricas (top aerolíneas y rutas)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8409763-c513-4af7-a8f3-1f808f8483c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_airlines_business = df_business['airline'].value_counts().nlargest(10).index.tolist()\n",
    "df_business['airline_top'] = df_business['airline'].apply(lambda x: x if x in top_airlines_business else 'other')\n",
    "df_business = pd.get_dummies(df_business, columns=['airline_top', 'route'], drop_first=True)\n",
    "\n",
    "top_airlines_economy = df_economy['airline'].value_counts().nlargest(10).index.tolist()\n",
    "df_economy['airline_top'] = df_economy['airline'].apply(lambda x: x if x in top_airlines_economy else 'other')\n",
    "df_economy = pd.get_dummies(df_economy, columns=['airline_top', 'route'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa281f00-ef7f-4367-a746-4db53f851753",
   "metadata": {},
   "source": [
    "\n",
    "**PASO 8. Imputación de nulos en nuevas columnas numéricas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534f9c00-50ec-4c3b-883b-1124ca6eb27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['time_taken_min', 'stop_num']:\n",
    "    df_business[col] = df_business[col].fillna(df_business[col].median())\n",
    "    df_economy[col] = df_economy[col].fillna(df_economy[col].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9837327d-90b7-4e23-b4f7-bcedcfefda74",
   "metadata": {},
   "source": [
    "**PASO 9. Eliminar columnas irrelevantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23040ad-a498-4943-a2fd-596f4e1d99af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['ch_code', 'dep_time', 'arr_time', 'airline', 'from', 'to', 'time_taken', 'stop']\n",
    "df_business = df_business.drop(cols_to_drop, axis=1)\n",
    "df_economy = df_economy.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6689dd6-6e36-453d-ac7a-18e13982cabe",
   "metadata": {},
   "source": [
    "**PASO 10. Análisis exploratorio visual (EDA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661011a2-b1f7-4150-927f-644f482595a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Limpieza y conversión de 'price' =====\n",
    "for df in [df_business, df_economy]:\n",
    "    df['price'] = (\n",
    "        df['price']\n",
    "        .astype(str)              # asegurar que sea string\n",
    "        .str.replace(',', '', regex=False)  # quitar comas\n",
    "        .str.strip()              # quitar espacios\n",
    "    )\n",
    "    df['price'] = pd.to_numeric(df['price'], errors='coerce')  # convertir a numérico\n",
    "\n",
    "# Eliminar nulos resultantes\n",
    "df_business = df_business[df_business['price'].notnull()].copy()\n",
    "df_economy = df_economy[df_economy['price'].notnull()].copy()\n",
    "\n",
    "print(\"✅ Limpieza de 'price' completada\")\n",
    "print(\"Business shape:\", df_business.shape)\n",
    "print(\"Economy shape:\", df_economy.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d23c7e2-a69d-4df3-bc3f-8c220be45b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Histograma con KDE para distribución de precios =====\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(df_business['price'], kde=True, color='red', label='Business', bins=50)\n",
    "sns.histplot(df_economy['price'], kde=True, color='blue', label='Economy', bins=50)\n",
    "plt.legend()\n",
    "plt.title('Distribución de precios: Business vs Economy')\n",
    "plt.xlabel('Precio')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fe501b-8983-4431-a633-6dbd5af366a3",
   "metadata": {},
   "source": [
    "# **Variables más importantes para price (correlaciones)**\n",
    "\n",
    "- La variable stop_num (cantidad de escalas) tiene la correlación más alta con el precio (0.59), seguida por time_taken_min (duración del vuelo, 0.24) y num_code (0.22).\n",
    "\n",
    "- day_of_week y month muestran correlaciones bajas, pero podrían tener efectos no lineales.\n",
    "\n",
    "- Implicaciones: el modelo debe priorizar variables como escalas y duración del vuelo, mientras que otras variables con baja correlación aún pueden ser útiles para capturar relaciones complejas.\n",
    "\n",
    "**Síntesis:**\n",
    "\n",
    "- Los precios dependen principalmente de la cantidad de escalas y duración del vuelo, y existen diferencias marcadas entre clases (Business vs Economy).\n",
    "\n",
    "- Esto valida la elección de modelos no lineales y la necesidad de un preprocesamiento cuidadoso, incluyendo ingeniería de variables y manejo de outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60f5ddf-4edd-4d7d-a9d7-40ff771b0fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Definir colormap armonioso: azul medio -> blanco -> rojo profundo\n",
    "colors = [\"#1f4e79\", \"#f0f0f0\", \"#b30000\"]  # azul medio, gris claro, rojo profundo\n",
    "cmap = LinearSegmentedColormap.from_list(\"blue_white_red_professional\", colors)\n",
    "\n",
    "# Correlación de variables numéricas\n",
    "corr = df_business[['price', 'stop_num', 'time_taken_min', 'num_code', 'day_of_week', 'month']].corr()\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=cmap,\n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"shrink\":0.8, \"label\":\"Correlación\"}\n",
    ")\n",
    "plt.title(\"Mapa de correlaciones de variables numéricas\", fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25ac5b9-c604-40ac-b6fa-73b2aea058b0",
   "metadata": {},
   "source": [
    "# **Conclusión del análisis exploratorio visual y correlaciones**\n",
    "\n",
    "- Distribución de precios (Business vs Economy)\n",
    "\n",
    "- Business tiene precios más altos y una cola larga de valores extremos, mostrando gran dispersión.\n",
    "\n",
    "- Economy está más concentrada en rangos bajos-medios, con menos valores extremos.\n",
    "\n",
    "- Ambas distribuciones están sesgadas a la derecha, indicando que la media no representa completamente la tendencia central.\n",
    "\n",
    "**Implicaciones: se recomienda realizar transformación del target (price) y manejo de outliers para mejorar el desempeño de los modelos. Además, los modelos no lineales (Random Forest, XGBoost) son más adecuados que modelos lineales simples (Lasso).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4d3581-4201-4fc8-b540-2c9c799c5d01",
   "metadata": {},
   "source": [
    "\n",
    "**PASO 11. Modelado: entrenamiento y evaluación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0b5436-f718-4842-a2ea-f6ac573124c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ==============================\n",
    "# Separar features y target\n",
    "# ==============================\n",
    "X = df_business.drop('price', axis=1)\n",
    "y = df_business['price']\n",
    "\n",
    "# Procesar columna de fecha\n",
    "# ==============================\n",
    "if 'date' in X.columns:\n",
    "    X['year'] = X['date'].dt.year\n",
    "    X['month'] = X['date'].dt.month\n",
    "    X['day'] = X['date'].dt.day\n",
    "    X['weekday'] = X['date'].dt.weekday\n",
    "    X['is_weekend'] = X['date'].dt.weekday >= 5\n",
    "    X = X.drop(columns=['date'])\n",
    "\n",
    "print(\"Columnas después de procesar fechas:\")\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5aaf8a-0f03-465a-846a-dafce0c88654",
   "metadata": {},
   "source": [
    "Limpieza de Fecha: Convertimos la columna date en varias variables derivadas (year, month, day, weekday, is_weekend) para capturar estacionalidad y patrones según día y mes. Además, verificamos los tipos de datos resultantes para asegurar compatibilidad con los modelos de Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b022750a-9cd8-4f0b-96f4-e0f858807af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamiento y limpieza de fechas\n",
    "\n",
    "X = df_business.drop('price', axis=1)\n",
    "y = df_business['price']\n",
    "\n",
    "# Si existe la columna date, procesarla\n",
    "if 'date' in X.columns:\n",
    "    X['year'] = X['date'].dt.year\n",
    "    X['month'] = X['date'].dt.month\n",
    "    X['day'] = X['date'].dt.day\n",
    "    X['weekday'] = X['date'].dt.weekday\n",
    "    X['is_weekend'] = (X['date'].dt.weekday >= 5).astype(int)  # 0 o 1\n",
    "\n",
    "    # 🔥 eliminar definitivamente la columna date\n",
    "    X = X.drop(columns=['date'])\n",
    "\n",
    "print(\"Dtypes después de limpiar fechas:\")\n",
    "print(X.dtypes)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639f2028",
   "metadata": {},
   "source": [
    "**División en test y train**\n",
    "\n",
    "**Entrenamiento y Evaluación de modelos: RandomForest, Lasso, y XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d37d0a-ee7d-4a46-a340-9faf00f16b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# División train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Modelos\n",
    "models = {\n",
    "    'RandomForest': RandomForestRegressor(random_state=42),\n",
    "    'Lasso': Lasso(alpha=0.01, random_state=42),   # alpha pequeño para no penalizar demasiado\n",
    "    'XGBoost': XGBRegressor(random_state=42, n_estimators=200, learning_rate=0.1)\n",
    "}\n",
    "\n",
    "# Entrenar y evaluar\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nEntrenando {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"{name} → RMSE: {rmse:.2f}, R²: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd21c93d-00f7-4c92-8b1a-b0fd45866ae0",
   "metadata": {},
   "source": [
    "                                   Comparación de modelos para predicción de precio de vuelos\n",
    "\n",
    "| Modelo        | RMSE    | R²     | Comentario                                                                              |\n",
    "| ------------- | ------- | ------ | --------------------------------------------------------------------------------------- |\n",
    "| Random Forest | 3626.39 | 0.9222 | Mejor desempeño, captura relaciones no lineales, más robusto frente a outliers          |\n",
    "| Lasso         | 8803.48 | 0.5417 | Peor desempeño, modelo lineal simple, no maneja bien la distribución sesgada del target |\n",
    "| XGBoost       | 4759.55 | 0.8660 | Bueno, cercano a Random Forest, permite cierta regularización y no linealidad           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b4364d",
   "metadata": {},
   "source": [
    "**Optimización de RandomForest con GridSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0dc871-91c6-488d-8534-4395a212c821",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Definir grid de hiperparámetros\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2,5],\n",
    "    'min_samples_leaf': [1,2]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=3, scoring='r2', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mejor modelo\n",
    "print(\"Mejores parámetros RandomForest:\", grid_search.best_params_)\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Predicciones\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "# Métricas\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"RandomForest Optimizado → RMSE: {rmse_rf:.2f}, R²: {r2_rf:.4f}, MAE: {mae_rf:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3330ea18",
   "metadata": {},
   "source": [
    "Se realizó una búsqueda de hiperparámetros para RandomForest utilizando **GridSearchCV** con validación cruzada (cv=3).  \n",
    "El modelo optimizado mejoró respecto al baseline y a la versión sin tuning, mostrando un ajuste sólido con buen equilibrio entre **precisión (R²)** y **error absoluto (MAE)**.\n",
    "\n",
    "Mejores parámetros RandomForest: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
    "RandomForest Optimizado → RMSE: 3604.44, R²: 0.9232, MAE: 1708.94\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3c2788-e17f-42ff-9bbc-25a24e7458db",
   "metadata": {},
   "source": [
    "**PASO 12. Evaluación y comparación de modelos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971a8611-9696-43ac-a4d9-e6baa6741399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣ Importar librerías necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# 2️⃣ Función de evaluación de modelos\n",
    "def evaluate(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))  # RMSE manual para compatibilidad\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return mae, rmse, r2\n",
    "\n",
    "# 3️⃣ Evaluar cada modelo del diccionario 'models'\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    results[name] = evaluate(model, X_test, y_test)\n",
    "\n",
    "# 4️⃣ Convertir resultados en DataFrame\n",
    "metrics_df = pd.DataFrame(results, index=['MAE', 'RMSE', 'R2']).T\n",
    "metrics_df.index.name = 'Modelo'\n",
    "metrics_df.columns.name = 'Métrica'\n",
    "\n",
    "# 5️⃣ Graficar comparación de métricas\n",
    "metrics_df.plot(kind='bar', figsize=(10,6))\n",
    "plt.title('Comparación de métricas entre modelos')\n",
    "plt.ylabel('Valor')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# 6️⃣ Evaluación de baseline: predecir la media de y_train\n",
    "y_pred_baseline = np.full(shape=y_test.shape, fill_value=y_train.mean(), dtype=np.float64)\n",
    "mae_base = mean_absolute_error(y_test, y_pred_baseline)\n",
    "rmse_base = np.sqrt(mean_squared_error(y_test, y_pred_baseline))\n",
    "r2_base = r2_score(y_test, y_pred_baseline)\n",
    "print(f\"Baseline (media): MAE={mae_base:.2f}, RMSE={rmse_base:.2f}, R2={r2_base:.2f}\")\n",
    "\n",
    "# 7️⃣ Comparación con baseline en gráfico adicional (opcional)\n",
    "baseline_df = metrics_df.copy()\n",
    "baseline_df.loc['Baseline'] = [mae_base, rmse_base, r2_base]\n",
    "\n",
    "baseline_df.plot(kind='bar', figsize=(10,6))\n",
    "plt.title('Comparación modelos vs Baseline')\n",
    "plt.ylabel('Valor')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e174bf0-f729-44ff-9793-03ed8c50e29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣ DataFrame con baseline incluido\n",
    "metrics_full_df = metrics_df.copy()\n",
    "metrics_full_df.loc['Baseline'] = [mae_base, rmse_base, r2_base]\n",
    "\n",
    "# 2️⃣ Configuración del gráfico\n",
    "fig, ax1 = plt.subplots(figsize=(12,6))\n",
    "\n",
    "x = np.arange(len(metrics_full_df))\n",
    "bar_width = 0.35\n",
    "\n",
    "# Barras MAE y RMSE en eje principal\n",
    "ax1.bar(x - bar_width/2, metrics_full_df['MAE'], width=bar_width, label='MAE', color='skyblue')\n",
    "ax1.bar(x + bar_width/2, metrics_full_df['RMSE'], width=bar_width, label='RMSE', color='salmon')\n",
    "ax1.set_ylabel('MAE / RMSE')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(metrics_full_df.index)\n",
    "ax1.set_title('Comparación de métricas por modelo (incluyendo Baseline)')\n",
    "ax1.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# 3️⃣ R² en eje secundario\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(x, metrics_full_df['R2'], color='green', marker='o', linestyle='-', label='R²', linewidth=2)\n",
    "ax2.set_ylabel('R²')\n",
    "ax2.set_ylim(0,1)  # opcional: normalizar R² entre 0 y 1 para mejor visualización\n",
    "\n",
    "# 4️⃣ Leyenda combinada\n",
    "bars_labels = ax1.get_legend_handles_labels()\n",
    "line_labels = ax2.get_legend_handles_labels()\n",
    "ax1.legend(bars_labels[0] + line_labels[0], bars_labels[1] + line_labels[1], loc='upper right')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcf30b2-59e9-4f14-b59d-c1b331546124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline\n",
    "y_pred_base = np.full_like(y_test, y_train.mean())\n",
    "mae_base = mean_absolute_error(y_test, y_pred_base)\n",
    "rmse_base = np.sqrt(mean_squared_error(y_test, y_pred_base))\n",
    "r2_base = r2_score(y_test, y_pred_base)\n",
    "\n",
    "print(\"Baseline (media) → MAE: {:.2f}, RMSE: {:.2f}, R2: {:.4f}\".format(mae_base, rmse_base, r2_base))\n",
    "\n",
    "# Comparación final\n",
    "print(\"\\nConclusión:\")\n",
    "print(\"- RandomForest y XGBoost superan ampliamente el baseline y Lasso.\")\n",
    "print(\"- Variables más relevantes según correlación: time_taken_min, stop_num, month, day_of_week.\")\n",
    "print(\"- La data tiene outliers y colas largas en Business, por lo que modelos no lineales funcionan mejor.\")\n",
    "print(\"- Próximos pasos: tratar outliers, evaluar transformaciones logarítmicas, ajustar hiperparámetros XGBoost y evaluar Economy.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80acda25-5d35-4cae-a07a-e3dbd276b8b2",
   "metadata": {},
   "source": [
    "# Conclusión del proyecto de predicción de precios de vuelos\n",
    "\n",
    "## Resumen ejecutivo\n",
    "\n",
    "- Se entrenaron tres modelos: **Random Forest**, **Lasso** y **XGBoost** para predecir el precio de boletos de avión (Business).  \n",
    "- Se compararon sus métricas frente a un **baseline** simple (predecir la media de `price`).  \n",
    "- Se aplicaron transformaciones de fechas, codificación de aerolíneas y rutas, y feature engineering para escalas y duración del vuelo.  \n",
    "- La distribución de precios presenta **outliers y colas largas**, por lo que los modelos **no lineales** funcionan mejor.\n",
    "\n",
    "---\n",
    "\n",
    "## Comparación de modelos\n",
    "\n",
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Modelo</th>\n",
    "<th>RMSE</th>\n",
    "<th>MAE</th>\n",
    "<th>R²</th>\n",
    "<th>Comentario</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr style=\"background-color:#c6efce;\"> \n",
    "<td>Random Forest</td>\n",
    "<td>3604.44</td>\n",
    "<td>1708.94</td>\n",
    "<td>0.9232</td>\n",
    "<td>Mejor desempeño, captura relaciones no lineales y robusto frente a outliers</td>\n",
    "</tr>\n",
    "<tr style=\"background-color:#ffc7ce;\"> \n",
    "<td>Lasso</td>\n",
    "<td>8803.48</td>\n",
    "<td>5342.01</td>\n",
    "<td>0.5417</td>\n",
    "<td>Peor desempeño, modelo lineal simple, no maneja bien la distribución sesgada del target</td>\n",
    "</tr>\n",
    "<tr style=\"background-color:#ffeb9c;\"> \n",
    "<td>XGBoost</td>\n",
    "<td>4759.55</td>\n",
    "<td>2087.23</td>\n",
    "<td>0.8660</td>\n",
    "<td>Buen desempeño, cercano a Random Forest, permite regularización y relaciones no lineales</td>\n",
    "</tr>\n",
    "<tr style=\"background-color:#d9d9d9;\"> \n",
    "<td>Baseline</td>\n",
    "<td>13004.97</td>\n",
    "<td>9732.75</td>\n",
    "<td>-0.0001</td>\n",
    "<td>Línea base (media de `price`), muestra la ventaja de los modelos predictivos</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusión final\n",
    "\n",
    "1. **Random Forest** es el modelo más recomendado, seguido de **XGBoost**.  \n",
    "2. Las variables más relevantes son: `stop_num` (cantidad de escalas), `time_taken_min` (duración del vuelo), `month` y `day_of_week`.  \n",
    "3. Los modelos lineales simples (Lasso) no son adecuados para esta distribución de precios.  \n",
    "4. **Próximos pasos**:  \n",
    "   - Tratar outliers y colas largas (Business).  \n",
    "   - Evaluar transformaciones logarítmicas de `price`.  \n",
    "   - Ajustar hiperparámetros de XGBoost.  \n",
    "   - Aplicar la misma metodología a la clase **Economy** para comparar resultados.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
